{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sgkit as sg\n",
    "import allel\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.utils.extmath import row_norms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treemix takes a tab delimited file of allele counts by population - let's define our populations here based on the countries and the pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = sg.load_dataset('/home/dennist/lstm_data/cease/variants_bycohort/combined_cohorts/zarr/combined_cohorts.CM023249.zarr/')\n",
    "\n",
    "#load and filter metadata\n",
    "#load and filter metadata\n",
    "df_samples = pd.read_table('/home/dennist/lstm_data/cease/variant_metadata/cease.combined.metadata.20240703.txt')\n",
    "df_samples = df_samples[df_samples['qc_pass'] == 1].sort_values('order').reset_index()\n",
    "\n",
    "#extract gts\n",
    "gt = allel.GenotypeArray(ds.call_genotype)\n",
    "\n",
    "\n",
    "#next, ld prune. this takes a wee while"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ld_prune(gn, size, step, threshold=.1, n_iter=1):\n",
    "    for i in range(n_iter):\n",
    "        loc_unlinked = allel.locate_unlinked(gn, size=size, step=step, threshold=threshold)\n",
    "        n = np.count_nonzero(loc_unlinked)\n",
    "        n_remove = gn.shape[0] - n\n",
    "        print('iteration', i+1, 'retaining', n, 'removing', n_remove, 'variants')\n",
    "    return loc_unlinked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 1 retaining 150014 removing 349986 variants\n",
      "iteration 2 retaining 150014 removing 349986 variants\n"
     ]
    }
   ],
   "source": [
    "n = 500000  # number of SNPs to choose randomly\n",
    "vidx = np.random.choice(gt.shape[0], n, replace=False)\n",
    "vidx.sort()\n",
    "gtr = gt.take(vidx, axis=0)\n",
    "gnr = gtr.to_n_alt()\n",
    "locun = ld_prune(gnr, size=500, step=200, threshold=.1, n_iter=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150014"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(locun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_u = gtr.compress(locun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty dictionary to store row indices for each level\n",
    "pop_dict = {}\n",
    "\n",
    "# Iterate through unique levels in the 'factor_column'\n",
    "for level in df_samples['analysis_pop'].unique():\n",
    "    # Get the row indices where the 'factor_column' matches the current level\n",
    "    indices = df_samples.index[df_samples['analysis_pop'] == level].tolist()\n",
    "    \n",
    "    # Store the indices in the dictionary with the level as the key\n",
    "    pop_dict[level] = indices\n",
    "\n",
    "# Remove dictionary entries with fewer than 5 values\n",
    "pop_dict = {key: value for key, value in pop_dict.items() if len(value) >= 5}\n",
    "\n",
    "#get all pops too\n",
    "pop_dict['all']  = df_samples.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac_subpop = gt_u.count_alleles_subpops(pop_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count alleles by pop & convert to table\n",
    "ac_subpop = gt.count_alleles_subpops(pop_dict)\n",
    "#get segregating variants only\n",
    "is_seg = ac_subpop['all'].is_segregating()[:]\n",
    "\n",
    "combined_data = {}\n",
    "\n",
    "# Process each item in the dictionary\n",
    "for name, array in ac_subpop.items():\n",
    "    # Check if the array has at least two columns\n",
    "\n",
    "    #get seg sites\n",
    "    array = array.compress(is_seg)\n",
    "    if array.shape[1] < 2:\n",
    "        raise ValueError(f\"Array {name} does not have at least two columns\")\n",
    "    \n",
    "    # Combine each element of the two columns into a single string\n",
    "    combined_array = np.array([f\"{row[0]},{row[1]}\" for row in array])\n",
    "    \n",
    "    # Store the resulting array in the combined_data dictionary\n",
    "    combined_data[name] = combined_array\n",
    "\n",
    "# Convert the combined data into a DataFrame\n",
    "ac_df = pd.DataFrame(combined_data)\n",
    "\n",
    "##subsample randomly instead of ld pruning\n",
    "df_sample = ac_df.sample(frac=0.1)\n",
    "\n",
    "df_sample = df_sample.drop('all', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try to permute across different randomly chosen sets (10 times?)\n",
    "\n",
    "!mkdir /home/dennist/lstm_scratch/cease_workspace/treemix_20240711_permutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 1 retaining 156682 removing 343318 variants\n",
      "iteration 1 retaining 156126 removing 343874 variants\n",
      "iteration 1 retaining 157239 removing 342761 variants\n",
      "iteration 1 retaining 156130 removing 343870 variants\n",
      "iteration 1 retaining 156020 removing 343980 variants\n",
      "iteration 1 retaining 156072 removing 343928 variants\n",
      "iteration 1 retaining 156406 removing 343594 variants\n",
      "iteration 1 retaining 156342 removing 343658 variants\n",
      "iteration 1 retaining 155990 removing 344010 variants\n"
     ]
    }
   ],
   "source": [
    "for i in range(9):\n",
    "    vidx = np.random.choice(gt.shape[0], n, replace=False)\n",
    "    vidx.sort()\n",
    "    gtr = gt.take(vidx, axis=0)\n",
    "    gnr = gtr.to_n_alt()\n",
    "    locun = ld_prune(gnr, size=500, step=200, threshold=.1, n_iter=1)\n",
    "    ac_subpop = gt_u.count_alleles_subpops(pop_dict)\n",
    "\n",
    "    #count alleles by pop & convert to table\n",
    "    ac_subpop = gt.count_alleles_subpops(pop_dict)\n",
    "    #get segregating variants only\n",
    "    is_seg = ac_subpop['all'].is_segregating()[:]\n",
    "\n",
    "    combined_data = {}\n",
    "\n",
    "    # Process each item in the dictionary\n",
    "    for name, array in ac_subpop.items():\n",
    "        # Check if the array has at least two columns\n",
    "\n",
    "        #get seg sites\n",
    "        array = array.compress(is_seg)\n",
    "        if array.shape[1] < 2:\n",
    "            raise ValueError(f\"Array {name} does not have at least two columns\")\n",
    "        \n",
    "        # Combine each element of the two columns into a single string\n",
    "        combined_array = np.array([f\"{row[0]},{row[1]}\" for row in array])\n",
    "        \n",
    "        # Store the resulting array in the combined_data dictionary\n",
    "        combined_data[name] = combined_array\n",
    "\n",
    "    # Convert the combined data into a DataFrame\n",
    "    ac_df = pd.DataFrame(combined_data)\n",
    "\n",
    "    ##subsample randomly instead of ld pruning\n",
    "    df_sample = ac_df.sample(frac=0.1)\n",
    "\n",
    "    df_sample = df_sample.drop('all', axis=1)\n",
    "\n",
    "\n",
    "    df_sample.to_csv(f'/home/dennist/lstm_scratch/cease_workspace/treemix_20240711_permutes/pruned_bypop_afs.{i}.txt', sep='\\t', quoting=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample.to_csv('/home/dennist/lstm_scratch/cease_workspace/treemix_20240711/pruned_bypop_afs.txt', sep='\\t', quoting=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run treemix using the shell scripts\n",
    "#find optimal M if any using R script\n",
    "#optimal M looks like 0/1?\n",
    "#high data robustness...may plot without migration edges"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ceasebasic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
