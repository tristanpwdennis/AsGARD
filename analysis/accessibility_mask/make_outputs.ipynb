{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get stats\n",
    "from dask.diagnostics import ProgressBar\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import gzip\n",
    "from numba import jit\n",
    "from multiprocessing import Process\n",
    "\n",
    "\n",
    "# List of input files\n",
    "# Open the file in read mode\n",
    "with open('coverage_file.list', 'r') as file:\n",
    "# Create an empty list to store the lines\n",
    "    mapqfiles = []\n",
    "    # Iterate over the lines of the file\n",
    "    for line in file:\n",
    "        # Remove the newline character at the end of the line\n",
    "        line = line.strip()\n",
    "\n",
    "        # Append the line to the list\n",
    "        mapqfiles.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process a single file and extract a specific column by name\n",
    "def process_file(input_file, col_index):\n",
    "    with gzip.open(input_file, 'rt') as f:\n",
    "            column = np.loadtxt(input_file, delimiter='\\t', skiprows=1, usecols=col_index)  # Load data from the file, skipping the header\n",
    "            #olumn = data[:, col_index]  # Select the specified column\n",
    "            return column  # Remove the first row of the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after 'if' statement on line 2 (397862836.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[14], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(\"Calculating coverage statistics\")\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after 'if' statement on line 2\n"
     ]
    }
   ],
   "source": [
    "def infer_coverage_stats():\n",
    "    if __name__ == \"__main__\":\n",
    "        #get modal coverages\n",
    "        with open('data/modes.pkl', 'rb') as f:\n",
    "            modes = pkl.load(f)\n",
    "\n",
    "        def return_ind_filter(array, mode):\n",
    "            zerocov = array == 0 \n",
    "            lowcov = array < (mode/2)\n",
    "            hicov = array > (mode*2)\n",
    "            return(zerocov, lowcov, hicov)\n",
    "\n",
    "        #for all inds\n",
    "        #make arrays containing all of the coverage stats\n",
    "        #then sum acdross them to get proportion of individuals pass/fail each condition\n",
    "\n",
    "        def return_summed_arrays():\n",
    "\n",
    "            zero_cov_arrays = []\n",
    "            low_cov_arrays = []\n",
    "            hi_cov_arrays = []\n",
    "\n",
    "            for mode, file in zip(modes, mapqfiles):\n",
    "\n",
    "                arr = process_file(file, col_index = 2)\n",
    "\n",
    "                print(f\"Calculating coverage stats for {file}, with a modal cov of {mode}\")\n",
    "\n",
    "                zerocov, lowcov, hicov = return_ind_filter(arr, mode)\n",
    "\n",
    "                zero_cov_arrays.append(zerocov)\n",
    "                low_cov_arrays.append(lowcov)\n",
    "                hi_cov_arrays.append(hicov)\n",
    "\n",
    "            zero_cov_arrays = np.stack(zero_cov_arrays)\n",
    "            low_cov_arrays = np.stack(low_cov_arrays)\n",
    "            hi_cov_arrays = np.stack(hi_cov_arrays)\n",
    "\n",
    "            zero_cov_bool = np.sum(zero_cov_arrays, axis=0) / len(mapqfiles)\n",
    "            low_cov_bool = np.sum(low_cov_arrays, axis=0) / len(mapqfiles)\n",
    "            hi_cov_bool = np.sum(hi_cov_arrays, axis=0) / len(mapqfiles)\n",
    "\n",
    "            return(zero_cov_bool, low_cov_bool, hi_cov_bool)\n",
    "\n",
    "\n",
    "        z,l,h = return_summed_arrays()\n",
    "\n",
    "        # open a file, where you ant to store the data\n",
    "        with open('data/coverage_summary_stats.pkl', 'wb') as f:\n",
    "            pkl.dump([z,l,h], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_mapq_stats():\n",
    "    if __name__ == \"__main__\":\n",
    "\n",
    "        #for all inds\n",
    "        #make arrays containing all of the coverage stats\n",
    "        #then sum acdross them to get proportion of individuals pass/fail each condition\n",
    "\n",
    "        def return_summed_arrays():\n",
    "\n",
    "            mapq_arrays = []\n",
    "\n",
    "            for file in mapqfiles:\n",
    "\n",
    "                arr = process_file(file, col_index = 7)\n",
    "\n",
    "                mapq = arr < 30\n",
    "\n",
    "                mapq_arrays.append(mapq)\n",
    "\n",
    "            mapq_arrays = np.stack(mapq_arrays)\n",
    "\n",
    "            mapq_arrays_bool = np.sum(mapq_arrays, axis=0) / len(mapqfiles)\n",
    "            \n",
    "            return(mapq_arrays_bool)\n",
    "\n",
    "        mq = return_summed_arrays()\n",
    "\n",
    "        # open a file, where you ant to store the data\n",
    "        with open('data/mapq_summary_stats.pkl', 'wb') as f:\n",
    "            pkl.dump(mq, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ppfrac():\n",
    "    if __name__ == \"__main__\":\n",
    "\n",
    "\n",
    "        def return_ind_filter(array, mode):\n",
    "            mapqlow = array < 30\n",
    "            return mapqlow\n",
    "\n",
    "        #for all inds\n",
    "        #make arrays containing all of the coverage stats\n",
    "        #then sum acdross them to get proportion of individuals pass/fail each condition\n",
    "\n",
    "        def return_summed_arrays():\n",
    "\n",
    "            pp_arrays = []\n",
    "\n",
    "            for file in mapqfiles:\n",
    "\n",
    "                pp = process_file(file, col_index = 3)\n",
    "\n",
    "                all = process_file(file, col_index = 2)\n",
    "\n",
    "                frac_pp = pp / all\n",
    "\n",
    "                ppbool = frac_pp < 0.9\n",
    "\n",
    "                pp_arrays.append(frac_pp)\n",
    "\n",
    "            pp_arrays = np.stack(pp_arrays)\n",
    "\n",
    "            mapq_arrays_bool = np.sum(mapq_arrays, axis=0) / len(mapqfiles)\n",
    "            \n",
    "            return(mapq_arrays_bool)\n",
    "\n",
    "        mq = return_summed_arrays()\n",
    "\n",
    "        # open a file, where you ant to store the data\n",
    "        with open('data/mapq_summary_stats.pkl', 'wb') as f:\n",
    "            pkl.dump(mq, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    array_2 = da.from_zarr(reads_pp[stripped]).compute()\n",
    "\n",
    "    prop_pp = np.nan_to_num(array_2 / array_1)\n",
    "\n",
    "    pplow = prop_pp > 0.9\n",
    "\n",
    "    arrays_pp_sum.append(arrays_pp_sum)\n",
    "\n",
    "    print(f\"finished calculating pp for {stripped}\")\n",
    "\n",
    "pp_arrays = np.stack(arrays_pp_sum)\n",
    "\n",
    "pp_arrays_bool = np.sum(pp_arrays, axis=0) / 105\n",
    "\n",
    "\n",
    "# open a file, where you ant to store the data\n",
    "with open('data/pp_sumstats.pkl', 'w"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ericmake",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
